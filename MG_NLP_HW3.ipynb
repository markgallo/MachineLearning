{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A positive and negative word list (Hu and Bing 2004) exists on CourseWorks (Files à HW_FILEs à HW3 àzip). Please create a function called gen_senti that Tokenizes arbitrary text and compares each token with the positive and negative lexicons of each dictionary and outputs the sentiment score, S.  Positive and negative words, pw and nw, count as a score of 1 and -1 respectively for each word matched.  The total count for pw and nw are pc and nc, respectively.  Each message sentiment, S, is normalized between -1 and 1.  Any text that does not any positive AND negative words would have to be ignored, and not scored. (60 points)\n",
    "\n",
    "For example: Let us say the following sentence was an input into the function “The darkest hour is among us in this time of gloom, however, we will prevail!”.  Let us say the negative words were darkest and gloom and positive words were prevail\n",
    "\n",
    "S = (-1 + -1 + 1) / 3 = -1/3 = -0.3333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\QMSS\\\\Spring\\\\NaturalLanguageProcessing\\\\Homework\\\\HW3'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\QMSS\\Spring\\NaturalLanguageProcessing\\Homework\\HW3\n"
     ]
    }
   ],
   "source": [
    "%cd \"D:\\QMSS\\Spring\\NaturalLanguageProcessing\\Homework\\HW3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make it so that the example provided could be tested the word darkest was added to the negative word lexicon and prevail was added to the positive word lexicon. Gloom was already within the negative word lexicon, so it did not require being added for the example provided to make sense.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wrought', 'yawn', 'zap', 'zapped', 'zaps', 'zealot', 'zealous', 'zealously', 'zombie', 'darkest']\n"
     ]
    }
   ],
   "source": [
    "with open(\"negative-words.txt\", \"r\") as f:\n",
    "    negText = f.read()\n",
    "negTokens = negText.split(\"\\n\") # This splits the text file into tokens on the new line character\n",
    "print(negTokens[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wowed', 'wowing', 'wows', 'yay', 'youthful', 'zeal', 'zenith', 'zest', 'zippy', 'prevail']\n"
     ]
    }
   ],
   "source": [
    "with open(\"positive-words.txt\", \"r\") as f:\n",
    "    posText = f.read()\n",
    "posTokens = posText.split(\"\\n\") # This splits the text file into tokens on the new line character\n",
    "print(posTokens[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_sent = \"The darkest hour is among us in this time of gloom, however, we will prevail!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def gen_senti(theText):\n",
    "    # Count positive words\n",
    "    numPosWords = 0\n",
    "    theTextTokens = word_tokenize(theText)\n",
    "    for word in theTextTokens:\n",
    "        if word in posTokens:\n",
    "            numPosWords += 1\n",
    "            \n",
    "    # Count negative words\n",
    "    numNegWords = 0\n",
    "    for word in theTextTokens:\n",
    "        if word in negTokens:\n",
    "            numNegWords += -1\n",
    "    \n",
    "    \n",
    "    \n",
    "    sum = (numPosWords + numNegWords)/(abs(numPosWords)+abs(numNegWords))\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3333333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_senti(the_sent) #The sentence would deemed generally negative "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code exists on CourseWorks (Files à HW_FILEs à HW3 àpy and crawler.py). Only run the crawler function once with the exact words you see for the_query = [‘positive words’, ‘negative words’].  Note: you only need to run fetch_crawl once, comment that part out after running it\n",
    "\n",
    "1. What is the function iterate_var? (10 points)\n",
    "2. What is the function grid_search_func? (10 points)\n",
    "3. For the exact sentence above “The darkest…” what sentiment score do you get from the function above? (5 points)\n",
    "4. The variable called the_result outputs the likelihood score for the text entered in my_sample as a negative_word or a positive_word. Meaning if the_result has scores of 0.75 and 0.25 for negative_word and positive_word, respectively, which means the_result is more likely to be a negative_word.  Run the code, what scores do you get for the the_result? (5 points)\n",
    "5. Change the ngram_range=(1,1) to ngram_range=(1,3), what scores do you get for the the_result and what observations can you make on why scores changed between uni-gram (1,1) and tri-gram(1,3)? (10 points)\n",
    "***Upload a zip file with your .py code and comments in code to answer questions above***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  The iterate_var function makes it so that Principal Component analysis can be performed on our tf-idf vectorized data frame. This function allows one to set a limit of how close to one we want the percentage of variance explained by each of the selected components to be allowed to get, as the var_fig, which is equal to the sume of explained ratios, is less than the target provided to the function. In the example provided PCA will only be applied when the sum of the explained variance ratios is less than or equal to the target variance, provided to the iterate_var function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def iterate_var(var_target):\n",
    "    var_fig = 0.0\n",
    "    cnt = 1\n",
    "    while var_fig <= var_target:\n",
    "        pca = PCA(n_components=cnt)\n",
    "        my_dim = pca.fit_transform(my_xform_tfidf)\n",
    "        var_fig = sum(pca.explained_variance_ratio_)   \n",
    "        cnt += 1\n",
    "    return my_dim, pca\n",
    "\n",
    "my_dim, pca = iterate_var(0.95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  The grid_search_func applies gird search CV to the model and saves the best model, the best score, and the best parameters. This function allows us to proceed forward knowing that we fitting the model that will predict at the highest level of accuracy, provided we set effective parameters for GridSearchCV to leverage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_func(param_grid, the_mode_in, the_vec_in, the_lab_in):\n",
    "    grid_search = GridSearchCV(the_mode_in, param_grid=param_grid, cv=5)\n",
    "    best_model = grid_search.fit(the_vec_in, the_lab_in)\n",
    "    max_score = grid_search.best_score_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    return best_model, max_score, best_params\n",
    "\n",
    "param_grid = {\"max_depth\": [10, 50, 100],\n",
    "              \"n_estimators\": [1, 4, 16, 32, 64]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. We get a primiarily negative score, with the sentence containing 58.59% negative words and 41.4123% positive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   negative_words  positive_words\n",
      "0        0.585877        0.414123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from crawlerHw3 import crawler_sol\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#array that contains what topics to crawl\n",
    "the_query = ['positive words', 'negative words']\n",
    "#number of document to crawl per topic\n",
    "num_docs = 100\n",
    "\n",
    "#initialize function\n",
    "my_func = crawler_sol()\n",
    "\n",
    "#call up crawler function and perform crawl, resultant dataframe contains 3 columns, basic wranged\n",
    "#data\n",
    "the_data = my_func.fetch_crawl(None, the_query, num_docs)\n",
    "\n",
    "#####\n",
    "my_vec = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "my_xform_vec = my_vec.fit_transform(the_data.body_basic).toarray()\n",
    "col_names = my_vec.get_feature_names()\n",
    "#count_list = dict(my_xform_vec.sum(axis=0)) #this gets word frequency counts into a dictionary\n",
    "\n",
    "my_xform_vec = pd.DataFrame(my_xform_vec, columns=col_names)\n",
    "#####\n",
    "\n",
    "#####\n",
    "my_vec_tfidf = TfidfVectorizer()\n",
    "\n",
    "my_xform_tfidf = my_vec_tfidf.fit_transform(the_data.body_basic).toarray()\n",
    "col_names = my_vec_tfidf.get_feature_names()\n",
    "\n",
    "my_xform_tfidf = pd.DataFrame(my_xform_tfidf, columns=col_names)\n",
    "\n",
    "#####\n",
    "#\n",
    "#clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "#\n",
    "#clf.fit(my_xform_tfidf, the_data.label)  \n",
    "#\n",
    "#my_sample = ['i hiked in the woods and ran into a bobcat']\n",
    "#test_text = my_vec_tfidf.transform(my_sample).toarray()\n",
    "#\n",
    "#clf.predict(test_text)\n",
    "\n",
    "#####\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def iterate_var(var_target):\n",
    "    var_fig = 0.0\n",
    "    cnt = 1\n",
    "    while var_fig <= var_target:\n",
    "        pca = PCA(n_components=cnt)\n",
    "        my_dim = pca.fit_transform(my_xform_tfidf)\n",
    "        var_fig = sum(pca.explained_variance_ratio_)   \n",
    "        cnt += 1\n",
    "    return my_dim, pca\n",
    "\n",
    "my_dim, pca = iterate_var(0.95)\n",
    "\n",
    "def grid_search_func(param_grid, the_mode_in, the_vec_in, the_lab_in):\n",
    "    grid_search = GridSearchCV(the_mode_in, param_grid=param_grid, cv=5)\n",
    "    best_model = grid_search.fit(the_vec_in, the_lab_in)\n",
    "    max_score = grid_search.best_score_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    return best_model, max_score, best_params\n",
    "\n",
    "param_grid = {\"max_depth\": [10, 50, 100],\n",
    "              \"n_estimators\": [1, 4, 16, 32, 64]}\n",
    "\n",
    "clf_pca = RandomForestClassifier()\n",
    "gridsearch_model, best, opt_params = grid_search_func(\n",
    "        param_grid, clf_pca, my_xform_tfidf, the_data.label)\n",
    "\n",
    "clf_pca = RandomForestClassifier()\n",
    "clf_pca.set_params(**gridsearch_model.best_params_)\n",
    "clf_pca.fit(my_dim, the_data.label)\n",
    "\n",
    "my_sample = ['The darkest hour is among us in this time of gloom, however, we will prevail!']\n",
    "test_text = my_vec_tfidf.transform(my_sample).toarray()\n",
    "test_text_pca = pca.transform(test_text)\n",
    "\n",
    "the_result = pd.DataFrame(clf_pca.predict_proba(test_text_pca))\n",
    "the_result.columns = clf_pca.classes_\n",
    "print (the_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. The variable called the_result outputs the likelihood score for the text entered in my_sample as a negative_word or a positive_word. Meaning if the_result has scores of 0.75 and 0.25 for negative_word and positive_word, respectively, which means the_result is more likely to be a negative_word. Run the code, what scores do you get for the the_result? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative_words</th>\n",
       "      <th>positive_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.585877</td>\n",
       "      <td>0.414123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   negative_words  positive_words\n",
       "0        0.585877        0.414123"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores we get are 0.585877 for negative words and 0.414123 for positive words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.\n",
    "\n",
    "The original running of the model would only leverage unigrams (1,1). However with the switch to (1,3) the model can now leverage unigrams and trigrams. \n",
    "\n",
    "The scores may have changed because the ngram represents the 'size' of the sequence of n terms in the given sample. A 1-gram word sequence would base scores on data being introduced as such: the,darkest,hour,is,among,us,etc. A 3-gram of trigram would introduce data in the following manner: the darkest hour, is among us, etc etc etc. \n",
    "\n",
    "The decrease in negative word representation and increase in positive word proportions may have been inspired from shrinking the data size, as a result of including both unigrams and trigrams. The only unigram sentance would take each word as its own and thus the size of the data was replicative of the length of the sentance. One trigrams became leverageable it allowed for the data set to shrink as now the groupings could contain 1 or 3 words of the 15 total. \n",
    "\n",
    "If we were to have only one trigram present and the resest unigram the size of the data set would shrink from 15 to 13 as the one trigram takes three of the orginal words and replaces them with one combination of all three words. This could have made it so that the positive words not made up a greater proportion of the sentance, and thus experienced an increase in how represented positive words were in the sentance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   negative_words  positive_words\n",
      "0        0.541667        0.458333\n"
     ]
    }
   ],
   "source": [
    "#array that contains what topics to crawl\n",
    "the_query = ['positive words', 'negative words']\n",
    "#number of document to crawl per topic\n",
    "num_docs = 100\n",
    "\n",
    "#initialize function\n",
    "my_func = crawler_sol()\n",
    "\n",
    "#call up crawler function and perform crawl, resultant dataframe contains 3 columns, basic wranged\n",
    "#data\n",
    "the_data = my_func.fetch_crawl(None, the_query, num_docs)\n",
    "\n",
    "#####\n",
    "my_vec = CountVectorizer(ngram_range=(1, 3)) #size of the number of in this case words that can be in each token\n",
    "\n",
    "my_xform_vec = my_vec.fit_transform(the_data.body_basic).toarray()\n",
    "col_names = my_vec.get_feature_names()\n",
    "#count_list = dict(my_xform_vec.sum(axis=0)) #this gets word frequency counts into a dictionary\n",
    "\n",
    "my_xform_vec = pd.DataFrame(my_xform_vec, columns=col_names)\n",
    "#####\n",
    "\n",
    "#####\n",
    "my_vec_tfidf = TfidfVectorizer()\n",
    "\n",
    "my_xform_tfidf = my_vec_tfidf.fit_transform(the_data.body_basic).toarray()\n",
    "col_names = my_vec_tfidf.get_feature_names()\n",
    "\n",
    "my_xform_tfidf = pd.DataFrame(my_xform_tfidf, columns=col_names)\n",
    "\n",
    "#####\n",
    "#\n",
    "#clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "#\n",
    "#clf.fit(my_xform_tfidf, the_data.label)  \n",
    "#\n",
    "#my_sample = ['i hiked in the woods and ran into a bobcat']\n",
    "#test_text = my_vec_tfidf.transform(my_sample).toarray()\n",
    "#\n",
    "#clf.predict(test_text)\n",
    "\n",
    "#####\n",
    "\n",
    "from sklearn.decomposition import PCA #dimension reduction \n",
    "\n",
    "def iterate_var(var_target):\n",
    "    var_fig = 0.0\n",
    "    cnt = 1\n",
    "    while var_fig <= var_target:\n",
    "        pca = PCA(n_components=cnt)\n",
    "        my_dim = pca.fit_transform(my_xform_tfidf)\n",
    "        var_fig = sum(pca.explained_variance_ratio_)   \n",
    "        cnt += 1\n",
    "    return my_dim, pca\n",
    "\n",
    "my_dim, pca = iterate_var(0.95)\n",
    "\n",
    "def grid_search_func(param_grid, the_mode_in, the_vec_in, the_lab_in):\n",
    "    grid_search = GridSearchCV(the_mode_in, param_grid=param_grid, cv=5)\n",
    "    best_model = grid_search.fit(the_vec_in, the_lab_in)\n",
    "    max_score = grid_search.best_score_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    return best_model, max_score, best_params\n",
    "\n",
    "param_grid = {\"max_depth\": [10, 50, 100],\n",
    "              \"n_estimators\": [1, 4, 16, 32, 64]}\n",
    "\n",
    "clf_pca = RandomForestClassifier()\n",
    "gridsearch_model, best, opt_params = grid_search_func(\n",
    "        param_grid, clf_pca, my_xform_tfidf, the_data.label)\n",
    "\n",
    "clf_pca = RandomForestClassifier()\n",
    "clf_pca.set_params(**gridsearch_model.best_params_)\n",
    "clf_pca.fit(my_dim, the_data.label)\n",
    "\n",
    "my_sample = ['The darkest hour is among us in this time of gloom, however, we will prevail!']\n",
    "test_text = my_vec_tfidf.transform(my_sample).toarray()\n",
    "test_text_pca = pca.transform(test_text)\n",
    "\n",
    "the_result = pd.DataFrame(clf_pca.predict_proba(test_text_pca))\n",
    "the_result.columns = clf_pca.classes_\n",
    "print (the_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
