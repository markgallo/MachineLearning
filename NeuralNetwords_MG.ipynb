{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gallo_ML_Final",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkNJUtzV-aLQ",
        "colab_type": "text"
      },
      "source": [
        "1.  From the perspective of a social scientist, which models did we learn this semester that are useful for ruling out alternative explanations through control variables AND that allow us to observe substantively meaningful information from model coefficients?\n",
        "\n",
        "- a Regression model allows for this as the inclusion of control variables, say medium income, allow one to leverage a model that says, when variables such as income are held constant the variation in the dependent variable y can be explained by the variation in the x (independent variable) of interest. \n",
        "\n",
        "- The regression models we used were Lasso, Ridge, OLS Linear, Logistic Regression, Support Vector Regression, and Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgkL18GZ-p3Q",
        "colab_type": "text"
      },
      "source": [
        "2. Describe the main differences between supervised and unsupervised learning.\n",
        "\n",
        "- The key difference stems from the type of data used to train the models and the conclusions that can then be drawn. Supervised learners will leverage data that is already been labeled (ex: Logistic Classification), while unsupervised learners try to predict outcomes without the help of labels (ex: K-means). One can learn from supervised learners how well an approach classifies, a measure used to determine this may be accuracy or precision. Unsupervised learners premote the understanding of a data set, as it clusters data based on statistical similarities.  One could deduce then that objects of a certain characterisitc tend to have \"x\" in common using unsuperivsed learners. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgQ5ah2_A2xI",
        "colab_type": "text"
      },
      "source": [
        "3. Is supervised or unsupervised learning the primary approach that is used by machine learning practitioners?  For whatever approach you think is secondary, why would you use this approach (what's a good reason to use these kinds of models?)\n",
        "\n",
        "- The primary approach would be unsupervised because it is often easier to obtain unlabeled data than it is labeld data (Class 9, Slide 4). It is a good approach for one who is trying to understand the data. For example if one has data regarding a set of products but there are too many to understand through human reading, one could use unsuperivsed learning methods to cluster the product on certain characteristcs to see if those characteristics lead to the  trends of characterisitcs that are associated with a certain products. The hw with the wines data set comes to mind. \n",
        "\n",
        "- The secondary approach is supervised learning because it allows for finding to be based on the labels the data have been assigned. The reason this approach is considered secondary is because labeled data is often more difficult to come across that unlabled data For example in the buisness world one may want to leverage customer complaints and the status of the review in an effort to see how succesfuly one could use the initial complaint to predict whether the  complaint that has been addressed and closed. One could introduce a quality to measure as well, in an effort to predict whether a certain complaint could be succesfully classified as adressed quickly, slowly, or not at all. \n",
        "\n",
        "- \"Primary\" in this case really depends on the data the ML practitioner is using, finding, or being given. In the class room we first did supervised first. Accuracy and Percision are simple measures to understand and provide a basis for learning going forward. But for those in industury who seldom have access to labeled data their initintial approach would likely be unsupervised. It really depends on the situation and the data the situation provides. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVl9FudgCt1h",
        "colab_type": "text"
      },
      "source": [
        "4. Which unsupervised learning modeling approaches did we cover this semester?  What are the major differences between these techniques?\n",
        "\n",
        "- Principal Component Analysis, K-means Clustering, and Hierarchical clustering. \n",
        "\n",
        "- PCA is used to reduce the dimensions of a data set by finding a sequence of linear combinations that have maximum variance, Kmeans is a clustering approach that groups points together by assuring that the clusters contain posits that have as small a within-cluster variation as possible, Hierarchical clustering starts with each point as its own cluster and merges the clusters with those that are closest to it utill all point are contained within one differentiated cluster. \n",
        "\n",
        "- The difference between the three approach stems from the technique used to cluster. PCA starts by determining core groups through maximum variance, kmeans clusters leverage minimum variance, and hierarchical gradudual combines points according to proximity untill all points are under one cluster. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4icfWOeMIvxv",
        "colab_type": "text"
      },
      "source": [
        "5. What are the main benefits of using Principal Components Analysis?\n",
        "\n",
        "- The main benifit of PCA is that it reduces the dimensions of the data set so it is easier for humans to comprehend, while making an effort to retain as much of the variation as possible. It also assists in making sure independent vairbales are not correlated with one another, preventing issues of autocorrelation, which is good to avoid as autocorrelation can lead to model interpretations that would sugges the model's independent vairables have more explanatory power than they actually do. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duyqr-nRKpAG",
        "colab_type": "text"
      },
      "source": [
        "6. Thinking about neural networks, what are three major differences between a deep multilayer perceptron network and a convolutional neural network model?  Be sure to define any key terms in your explanation.\n",
        "\n",
        "- Convolutional Nueral Networks utilize filters that apply a constant matrix of values so to detect edges. \n",
        "- Convolutional Nueral Networks can apply strited convolution, where data points are applied to the same filter values, but the matrix slides along the additional matrix, so that the constant filter is applied different to values across the orginal matrix. This allows one to be able to detect an object, say an apple, is contained within an image regardless of where the apple is located in the frame. \n",
        "- Multilayer Perceptron Networks spit data, so determine which unique combinations of data could be combined to assure that the figure in question will be correctly predicted. The network could split an 8 into circles and using the layers and then predict with the understanding that for something to be classified as an 8 it would need to contian something similar to two cirlces. Likewise the same could be done for a 9 which contains one circle and a line (Class 11, slide 21). The pattern the pixels take (1 for the presense of data 0 for empty space) can be split using layers and combined so to differentiate one shape (number) from another \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjKUwxufewqd",
        "colab_type": "text"
      },
      "source": [
        "### Necessary Imports/Installs for Models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMgg1aFYe6n1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c_RVoifevSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb247c18-1944-4da1-bdea-594eeefa579f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten, Dropout"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5MgYB39qBdN",
        "colab_type": "text"
      },
      "source": [
        "7. Write the keras code for a multilayer perceptron neural network with the following structure: Three hidden layers.  50 hidden units in the first hidden layer, 100 in the second, and 150 in the third.  Activate all hidden layers with relu.  The output layer should be built to classify to five categories.  Further, your optimization technique should be stochastic gradient descent.  (This code should simply build the architecture of the model.  You will not run it on real data.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA7qs6w8uaJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "bbde0cb4-e023-4e9b-9e0e-04e9d6daaaab"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(50, input_shape=(4,)),\n",
        "    Activation('relu'),\n",
        "    Dense(100),\n",
        "    Activation('relu'),\n",
        "    Dense(150),\n",
        "    Activation('relu'),\n",
        "    Dense(5),\n",
        "    Activation('softmax'),\n",
        "])\n",
        "\n",
        "model.compile(loss ='categorical_crossentropy',optimizer = \"sgd\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 50)                250       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               5100      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 150)               15150     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 755       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 21,255\n",
            "Trainable params: 21,255\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWXa07EFvVno",
        "colab_type": "text"
      },
      "source": [
        "8. Write the keras code for a multilayer perceptron neural network with the following structure: Two hidden layers.  75 hidden units in the first hidden layer and 150 in the second.  Activate all hidden layers with relu.  The output layer should be built to classify a binary dependent variable.  Further, your optimization technique should be stochastic gradient descent.  (This code should simply build the architecture of the model.  You will not run it on real data.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_3O6mrWvWYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "557157dd-de28-4ad0-92b7-fce4e576c445"
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(75, input_shape=(4,)),\n",
        "    Activation('relu'),\n",
        "    Dense(150),\n",
        "    Activation('relu'),\n",
        "    Dense(2),\n",
        "    Activation('softmax'),\n",
        "])\n",
        "\n",
        "model.compile(loss ='categorical_crossentropy',optimizer = \"sgd\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 75)                375       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 75)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 150)               11400     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 302       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 12,077\n",
            "Trainable params: 12,077\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYK36baLvmyx",
        "colab_type": "text"
      },
      "source": [
        "9.  Write the keras code for a convolutional neural network with the following structure: Two convolutional layers.  16 filters in the first layer and 28 in the second.  Activate all convolutional layers with relu.  Use max pooling after each convolutional layer with a 2 by 2 filter.  The output layer should be built to classify to ten categories.  Further, your optimization technique should be stochastic gradient descent.  (This code should simply build the architecture of the model.  You will not run it on real data.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmEEmsPJvn4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "da2c27e3-dd25-4fe2-b8a1-1588f4b7ad95"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size=3, activation = 'relu',input_shape =(150,150,3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(28, kernel_size=3, activation = 'relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss ='categorical_crossentropy',optimizer = \"sgd\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 148, 148, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 72, 72, 28)        4060      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 28)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 36288)             0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 36288)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                362890    \n",
            "=================================================================\n",
            "Total params: 367,398\n",
            "Trainable params: 367,398\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNYkH4mEyTk9",
        "colab_type": "text"
      },
      "source": [
        "10.  Write the keras code for a convolutional neural network with the following structure: Two convolutional layers.  32 filters in the first layer and 32 in the second.  Activate all convolutional layers with relu.  Use max pooling after each convolutional layer with a 2 by 2 filter.  Add two fully connected layers with 128 hidden units in each layer and relu activations.  The output layer should be built to classify to six categories.  Further, your optimization technique should be stochastic gradient descent.  (This code should simply build the architecture of the model.  You will not run it on real data.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfy8BFN9yYNJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "a9ff310e-d94a-47fd-da53-f917ea7cc134"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=3, activation = 'relu',input_shape =(150,150,3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(32, kernel_size=3, activation = 'relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss ='categorical_crossentropy',optimizer = \"sgd\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 72, 72, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 36, 36, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 41472)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               5308544   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 6)                 774       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 5,335,974\n",
            "Trainable params: 5,335,974\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}